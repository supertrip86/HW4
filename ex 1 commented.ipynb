{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eugenio Baldo, Giovanni Giunta and  Leonardo Masci - Group 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first exercise was to gain an understanding of hashing and the HyperLogLog algorithm, the state of the art when it comes to estimating the number of unique users.\n",
    "In order to accomplish this task we have consulted a number of resources, including the following paper ( http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf ) from which we got a lot of the formulas we then implemented in our HLL function.\n",
    "\n",
    "Our work for this exercise is articulated in three steps:\n",
    "1. Transform the given dataset into a set of binaries\n",
    "2. Implement our HLL function\n",
    "3. Estimate the number of unique elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the binary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import everything we need and visualise the given initial txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>844082e02a27ddee8d99ea1af94a2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff96d6665b5c59d3a70bb8f2ba4f10be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b64a85884e2b159829331c19e05dbac9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1c8836719e84867c26ba2cfeb372c53d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b66f73ffd9008d9c99159e164261df51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "0  844082e02a27ddee8d99ea1af94a2969\n",
       "1  ff96d6665b5c59d3a70bb8f2ba4f10be\n",
       "2  b64a85884e2b159829331c19e05dbac9\n",
       "3  1c8836719e84867c26ba2cfeb372c53d\n",
       "4  b66f73ffd9008d9c99159e164261df51"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('hash.txt', header=None)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is comprised of hexadecimal numbers. Therefore, in order to create our binary file we simply had to convert those numbers into binaries. A problem we encountered with this step was that not all the output values were of the same length, which created problems in the following steps. For this reason, we decided to add 0s as needed to reach the desired length for each binary value. We included the results in a txt file to avoid having the recreate this dataset every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possiamo rimuovere il print, no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"binaries.txt\", \"w\")\n",
    "\n",
    "for i, row in dataset.iterrows():            \n",
    "    bin_value = bin(int(row[0], 16))[2:].zfill(len(row[0]) * 4)\n",
    "    f.write(bin_value + '\\n')\n",
    "\n",
    "    if (i % 10000000) == 0:\n",
    "        print(i)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000010001000000100000101110000000101010001001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111111110010110110101100110011001011011010111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011011001001010100001011000100001001110001010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001110010001000001101100111000110011110100001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011011001101111011100111111111111011001000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  1000010001000000100000101110000000101010001001...\n",
       "1  1111111110010110110101100110011001011011010111...\n",
       "2  1011011001001010100001011000100001001110001010...\n",
       "3  0001110010001000001101100111000110011110100001...\n",
       "4  1011011001101111011100111111111111011001000000..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaries = pd.read_csv('binaries.txt', header=None)\n",
    "\n",
    "binaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing our HyperLogLog function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the size of the binaries and the amount of values we were working with, we decided that 16 would be a good number of bytes to determine the destination bucket of each value, as we would end up with 2^16 buckets. We also initialised a dictionary that had 0 as the value for every single bucket.\n",
    "\n",
    "We then counted the number of 0s found in each string binary value until the first 1 was encountered. Lastly, we confronted this number with the number already present for the corresponding bucket: if the new value was higher we substituted it. This way we ended up with a dictionary containing the highest amount of consecutive 0s for each bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# togliere il print?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 16\n",
    "values = [int(\"\".join(map(str, list(i))), 2) for i in itertools.product([0, 1], repeat=b)]\n",
    "db = {x: 0 for x in values}\n",
    "\n",
    "def hyperLogLog(binary, b):\n",
    "    bucket = int(binary[:b], 2)\n",
    "    rest = binary[b:]\n",
    "    count = 0\n",
    "    for char in rest:\n",
    "        if char == '0':\n",
    "            count += 1\n",
    "        else:\n",
    "            count += 1\n",
    "            break\n",
    "\n",
    "    if db[bucket] < count:\n",
    "        db[bucket] = count\n",
    "\n",
    "    if (i % 10000000) == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the function was ready, we applied it to our binary dataset and saved the resulting dictionary as a json file, again for easy future access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in binaries.iterrows():\n",
    "    binary = row[0]\n",
    "    hyperLogLog(binary, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"db.json\", \"w\") as outfile: \n",
    "    json.dump(db, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db.json') as f:\n",
    "    dt = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating amount of unique elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the formulas we found in the above mentioned paper, we calculated the following values based on our final dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_z(values):\n",
    "    z = 0\n",
    "    for x in values:\n",
    "        z += 2 ** (-x)\n",
    "    return z\n",
    "\n",
    "m = len(dt)\n",
    "values = list(dt.values())\n",
    "z = calc_z(values)\n",
    "alpha = 0.7213/(1 + 1.079 / m )\n",
    "E = round((alpha * float(m**2)) / z)\n",
    "error = 1.04 / (math.sqrt(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125674524"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0040625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we estimated that the cardinality of our initial dataset was of about 125 million, with an approximated error of 0.004."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
